{"version":3,"file":"58272.fe568f9f.iframe.bundle.js","mappings":";;;;;;;;;;AAcA;;;;AAIA;;AAEA;;;AAGA;;;;AAIA;;;;;;;;;;;AAWA;;;;;AAKA;;;AAGA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2CA;;AAEA;;;;;;;;;;;;;;;AAeA;;;;AAIA;;;;;AAKA;;;;AC3GA;;;;;;AAMA;;;;;;AAMA;;AAEA;AACA;;;;;;;AAOA;;;;;;;;;AASA;;;;AAIA;;;AAGA;;;;;AAKA;;;;;;;;;;AAUA;;;;;;;;;;;;;;;;;;;AAmBA;;;;;;;;;AASA;;;AAGA;AACA;;;AAGA;;;;AAIA;AACA;;;;;;;;;AASA;;AAEA;;;;;;;;;;;AAWA;;;;;;AAMA;;;;;;;;;AASA;;;;;AAKA;;;AAGA;;;;AAIA;;AAEA;;AAEA;;;;;;AAMA;AACA;AACA;AACA;AACA;;AAEA;;;;AC9JA;;;;AAIA;;AAEA;;AAEA;;;;AAIA;AACA;;AAEA;;;;;ACdA;;;AAGA;;;;AAIA;;;AAGA;;;;AAIA;;;AAGA;;;;;;;;;AASA;;;;;;;;AAQA;;AAEA;;;AAGA;;;AAGA;;;;AAIA;;;;;AAKA;;;AAGA;;;AAGA;AC7DA;AACA;AACA;;;AAGA;;;;AAIA;;;;;;;;;;AAUA;;;;;;;;;;;;;;;;;;;;AAoBA;;AAEA;AACA;;AAEA;;;;;;;;;;;AAWA;;;AAGA;;;;AAIA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AAgBA;;;;;;;;;;;;;;;;;;;;;AAqBA;;;AAGA;;;;AAIA;AAeA;AACA;;AAdA;;AAEA;;;;AAIA;;AAEA;AACA;AACA;;AAEA;;AC/HA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;;;;;;;;;;;;;AAcA;;AAEA;;AAEA;;;;;;;;;;;;;;AAcA;;AAEA;;;;;;;;;AASA;;AAEA;;;;;;;;;;;;;AAaA;;;;;;;;;;AAUA","sources":["webpack://axux/./node_modules/@arcgis/core/chunks/LineCallout.glsl.js","webpack://axux/./node_modules/@arcgis/core/chunks/LineMarker.glsl.js","webpack://axux/./node_modules/@arcgis/core/chunks/NativeLine.glsl.js","webpack://axux/./node_modules/@arcgis/core/chunks/Path.glsl.js","webpack://axux/./node_modules/@arcgis/core/chunks/Pattern.glsl.js","webpack://axux/./node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/attributes/PathVertexPosition.glsl.js"],"sourcesContent":["/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{s as e}from\"./vec2.js\";import{a as i}from\"./vec2f64.js\";import{Z as r}from\"./vec4f64.js\";import{SliceDraw as o}from\"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js\";import{AlignPixel as n}from\"../views/3d/webgl-engine/core/shaderLibrary/hud/AlignPixel.glsl.js\";import{HUD as t}from\"../views/3d/webgl-engine/core/shaderLibrary/hud/HUD.glsl.js\";import{HUDVisibility as a}from\"../views/3d/webgl-engine/core/shaderLibrary/hud/HUDVisibility.glsl.js\";import{multipassGeometryTest as l}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassGeometryTest.glsl.js\";import{addScreenSizePerspectiveAlignment as d}from\"../views/3d/webgl-engine/core/shaderLibrary/util/ScreenSizePerspective.glsl.js\";import{Float2PassUniform as s}from\"../views/3d/webgl-engine/core/shaderModules/Float2PassUniform.js\";import{Float4PassUniform as c}from\"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js\";import{FloatPassUniform as p}from\"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js\";import{glsl as g}from\"../views/3d/webgl-engine/core/shaderModules/interfaces.js\";import{ShaderBuilder as f}from\"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js\";import{VertexAttribute as v}from\"../views/3d/webgl-engine/lib/VertexAttribute.js\";function S(i){const r=new f,{vertex:S,fragment:b}=r;return S.include(n),r.include(t,i),r.include(o,i),r.attributes.add(v.UV0,\"vec2\"),S.uniforms.add(new c(\"viewport\",((e,i)=>i.camera.fullViewport)),new p(\"lineSize\",((e,i)=>e.size>0?Math.max(1,e.size)*i.camera.pixelRatio:0)),new s(\"pixelToNDC\",((i,r)=>e(m,2/r.camera.fullViewport[2],2/r.camera.fullViewport[3]))),new p(\"borderSize\",((e,i)=>null!=e.borderColor?i.camera.pixelRatio:0)),new s(\"screenOffset\",((i,r)=>e(m,i.horizontalScreenOffset*r.camera.pixelRatio,0)))),r.varyings.add(\"coverageSampling\",\"vec4\"),r.varyings.add(\"lineSizes\",\"vec2\"),i.multipassEnabled&&r.varyings.add(\"depth\",\"float\"),i.occlusionTestEnabled&&r.include(a),i.hasScreenSizePerspective&&d(S),S.code.add(g`\n    void main(void) {\n      ProjectHUDAux projectAux;\n      vec4 endPoint = projectPositionHUD(projectAux);\n\n      vec3 vpos = projectAux.posModel;\n      if (rejectBySlice(vpos)) {\n        gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n        return;\n      }\n    ${i.occlusionTestEnabled?g`\n      if (!testHUDVisibility(endPoint)) {\n        gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n        return;\n      }`:\"\"}\n\n    ${i.hasScreenSizePerspective?g`\n      vec3 perspectiveFactor = screenSizePerspectiveScaleFactor(projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n      vec2 screenOffsetScaled = applyScreenSizePerspectiveScaleFactorVec2(screenOffset, perspectiveFactor);\n        `:g`vec2 screenOffsetScaled = screenOffset;`}\n      // Add view dependent polygon offset to get exact same original starting point. This is mostly used to get the\n      // correct depth value\n      vec3 posView = (view * vec4(position, 1.0)).xyz;\n      ${i.multipassEnabled?\"depth = posView.z;\":\"\"}\n\n      applyHUDViewDependentPolygonOffset(auxpos1.w, projectAux.absCosAngle, posView);\n      vec4 startPoint = proj * vec4(posView, 1.0);\n      // Apply screen offset to both start and end point\n      vec2 screenOffsetNorm = screenOffsetScaled * 2.0 / viewport.zw;\n      startPoint.xy += screenOffsetNorm * startPoint.w;\n      endPoint.xy += screenOffsetNorm * endPoint.w;\n      // Align start and end to pixel origin\n      vec4 startAligned = alignToPixelOrigin(startPoint, viewport.zw);\n      vec4 endAligned = alignToPixelOrigin(endPoint, viewport.zw);\n    ${i.depthHudEnabled?i.depthHudAlignStartEnabled?g`endAligned = vec4(endAligned.xy / endAligned.w * startAligned.w, startAligned.zw);`:g`startAligned = vec4(startAligned.xy / startAligned.w * endAligned.w, endAligned.zw);`:\"\"}\n      vec4 projectedPosition = mix(startAligned, endAligned, uv0.y);\n      // The direction of the line in screen space\n      vec2 screenSpaceDirection = normalize(endAligned.xy / endAligned.w - startAligned.xy / startAligned.w);\n      vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x);\n    ${i.hasScreenSizePerspective?g`\n      float lineSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(lineSize, perspectiveFactor);\n      float borderSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(borderSize, perspectiveFactor);\n        `:g`\n      float lineSizeScaled = lineSize;\n      float borderSizeScaled = borderSize;\n        `}\n      float halfPixelSize = lineSizeScaled * 0.5;\n\n      // Compute full ndc offset, adding 1px padding for doing anti-aliasing and the border size\n      float padding = 1.0 + borderSizeScaled;\n      vec2 ndcOffset = (-halfPixelSize - padding + uv0.x * (lineSizeScaled + padding + padding)) * pixelToNDC;\n\n      // Offset x/y from the center of the line in screen space\n      projectedPosition.xy += perpendicularScreenSpaceDirection * ndcOffset * projectedPosition.w;\n\n      // Compute a coverage varying which we can use in the fragment shader to determine\n      // how much a pixel is actually covered by the line (i.e. to anti alias the line).\n      // This works by computing two coordinates that can be linearly interpolated and then\n      // subtracted to find out how far away from the line edge we are.\n      float edgeDirection = (uv0.x * 2.0 - 1.0);\n\n      float halfBorderSize = 0.5 * borderSizeScaled;\n      float halfPixelSizeAndBorder = halfPixelSize + halfBorderSize;\n      float outerEdgeCoverageSampler = edgeDirection * (halfPixelSizeAndBorder + halfBorderSize + 1.0);\n\n      float isOneSided = float(lineSizeScaled < 2.0 && borderSize < 2.0);\n\n      coverageSampling = vec4(\n        // Edge coordinate\n        outerEdgeCoverageSampler,\n\n        // Border edge coordinate\n        outerEdgeCoverageSampler - halfPixelSizeAndBorder * isOneSided,\n\n        // Line offset\n        halfPixelSize - 0.5,\n\n        // Border offset\n        halfBorderSize - 0.5 + halfPixelSizeAndBorder * (1.0 - isOneSided)\n      );\n\n      lineSizes = vec2(lineSizeScaled, borderSizeScaled);\n\n      gl_Position = projectedPosition;\n    }\n  `),b.uniforms.add(new c(\"uColor\",(e=>u(e.color))),new c(\"borderColor\",(e=>u(e.borderColor)))),i.multipassEnabled&&(b.include(l,i),b.uniforms.add(new s(\"inverseViewport\",((e,i)=>i.inverseViewport)))),b.code.add(g`\n    void main() {\n      ${i.multipassEnabled?\"if( geometryDepthTest(gl_FragCoord.xy * inverseViewport, depth) ){ discard; }\":\"\"}\n\n      // Mix between line and border coverage offsets depending on whether we need\n      // a border (based on the sidedness).\n      vec2 coverage = min(1.0 - clamp(abs(coverageSampling.xy) - coverageSampling.zw, 0.0, 1.0), lineSizes);\n\n      // Mix between border and line color based on the line coverage (conceptually the line blends on top of the\n      // border background).\n      //\n      // Anti-alias by blending final result using the full (including optional border) coverage and the color alpha\n      float borderAlpha = uColor.a * borderColor.a * coverage.y;\n      float colorAlpha = uColor.a * coverage.x;\n\n      float finalAlpha = mix(borderAlpha, 1.0, colorAlpha);\n\n    ${i.depthHudEnabled?g`\n      if (finalAlpha < 0.01) {\n        discard;\n      }\n      `:g`\n      vec3 finalRgb = mix(borderColor.rgb * borderAlpha, uColor.rgb, colorAlpha);\n      fragColor = vec4(finalRgb, finalAlpha);\n      `}\n  }\n  `),r}function u(e){return null!=e?e:r}const m=i(),b=Object.freeze(Object.defineProperty({__proto__:null,build:S},Symbol.toStringTag,{value:\"Module\"}));export{b as L,S as b};\n","/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{markerTextureSize as e,markerSymbolSize as r,markerTipThicknessFactor as o}from\"../views/3d/support/engineContent/marker.js\";import{addLinearDepth as i,addCalculateLinearDepth as a}from\"../views/3d/webgl-engine/core/shaderLibrary/ForwardLinearDepth.glsl.js\";import{ShaderOutput as t}from\"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js\";import{SliceDraw as n}from\"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js\";import{RibbonVertexPosition as s}from\"../views/3d/webgl-engine/core/shaderLibrary/attributes/RibbonVertexPosition.glsl.js\";import{OutputDepth as l}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js\";import{MarkerSizing as c}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MarkerSizing.glsl.js\";import{multipassTerrainTest as d}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js\";import{symbolAlphaCutoff as p}from\"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaCutoff.js\";import{ColorConversion as v}from\"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js\";import{RgbaFloatEncoding as m}from\"../views/3d/webgl-engine/core/shaderLibrary/util/RgbaFloatEncoding.glsl.js\";import{addProjViewLocalOrigin as f,addViewNormal as h,addPixelRatio as g}from\"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js\";import{Float2PassUniform as u}from\"../views/3d/webgl-engine/core/shaderModules/Float2PassUniform.js\";import{Float4PassUniform as w}from\"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js\";import{FloatPassUniform as y}from\"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js\";import{glsl as S}from\"../views/3d/webgl-engine/core/shaderModules/interfaces.js\";import{Matrix4PassUniform as b}from\"../views/3d/webgl-engine/core/shaderModules/Matrix4PassUniform.js\";import{ShaderBuilder as x}from\"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js\";import{Texture2DPassUniform as P}from\"../views/3d/webgl-engine/core/shaderModules/Texture2DPassUniform.js\";import{TransparencyPassType as z}from\"../views/3d/webgl-engine/lib/TransparencyPassType.js\";import{VertexAttribute as L}from\"../views/3d/webgl-engine/lib/VertexAttribute.js\";import{LineMarkerSpace as j,LineMarkerAnchor as C}from\"../views/3d/webgl-engine/shaders/LineMarkerTechniqueConfiguration.js\";function M(M){const D=new x,k=M.multipassEnabled&&(M.output===t.Color||M.output===t.Alpha),N=M.space===j.World;D.include(s,M),D.include(c,M),M.output===t.Depth&&D.include(l,M);const{vertex:T,fragment:A}=D;return A.include(m),f(T,M),D.attributes.add(L.POSITION,\"vec3\"),D.attributes.add(L.UV0,\"vec2\"),D.attributes.add(L.AUXPOS1,\"vec3\"),D.varyings.add(\"vColor\",\"vec4\"),D.varyings.add(\"vpos\",\"vec3\"),D.varyings.add(\"vUV\",\"vec2\"),D.varyings.add(\"vSize\",\"float\"),i(D),k&&D.varyings.add(\"depth\",\"float\"),M.hasTip&&D.varyings.add(\"vLineWidth\",\"float\"),T.uniforms.add(new u(\"nearFar\",((e,r)=>r.camera.nearFar)),new w(\"viewport\",((e,r)=>r.camera.fullViewport))),T.code.add(S`vec4 projectAndScale(vec4 pos) {\nvec4 posNdc = proj * pos;\nposNdc.xy *= viewport.zw / posNdc.w;\nreturn posNdc;\n}`),T.code.add(S`void clip(vec4 pos, inout vec4 prev) {\nfloat vnp = nearFar[0] * 0.99;\nif (prev.z > -nearFar[0]) {\nfloat interpolation = (-vnp - pos.z) / (prev.z - pos.z);\nprev = mix(pos, prev, interpolation);\n}\n}`),N?(D.attributes.add(L.NORMAL,\"vec3\"),h(T),T.constants.add(\"tiltThreshold\",\"float\",.7),T.code.add(S`vec3 perpendicular(vec3 v) {\nvec3 n = (viewNormal * vec4(normal.xyz, 1.0)).xyz;\nvec3 n2 = cross(v, n);\nvec3 forward = vec3(0.0, 0.0, 1.0);\nfloat tiltDot = dot(forward, n);\nreturn abs(tiltDot) < tiltThreshold ? n : n2;\n}`)):T.code.add(S`vec2 perpendicular(vec2 v) {\nreturn vec2(v.y, -v.x);\n}`),T.code.add(S`\n      #define vecN ${N?\"vec3\":\"vec2\"}\n\n      vecN normalizedSegment(vecN pos, vecN prev) {\n        vecN segment = pos - prev;\n        float segmentLen = length(segment);\n\n        // normalize or zero if too short\n        return (segmentLen > 0.001) ? segment / segmentLen : ${N?\"vec3(0.0, 0.0, 0.0)\":\"vec2(0.0, 0.0)\"};\n      }\n\n      vecN displace(vecN pos, vecN prev, float displacementLen) {\n        vecN segment = normalizedSegment(pos, prev);\n\n        vecN displacementDirU = perpendicular(segment);\n        vecN displacementDirV = segment;\n\n        ${M.anchor===C.Tip?\"pos -= 0.5 * displacementLen * displacementDirV;\":\"\"}\n\n        return pos + displacementLen * (uv0.x * displacementDirU + uv0.y * displacementDirV);\n      }\n    `),M.space===j.Screen&&(T.uniforms.add(new b(\"inverseProjectionMatrix\",((e,r)=>r.camera.inverseProjectionMatrix))),T.code.add(S`vec3 inverseProject(vec4 posScreen) {\nposScreen.xy = (posScreen.xy / viewport.zw) * posScreen.w;\nreturn (inverseProjectionMatrix * posScreen).xyz;\n}`),T.code.add(S`bool rayIntersectPlane(vec3 rayDir, vec3 planeOrigin, vec3 planeNormal, out vec3 intersection) {\nfloat cos = dot(rayDir, planeNormal);\nfloat t = dot(planeOrigin, planeNormal) / cos;\nintersection = t * rayDir;\nreturn abs(cos) > 0.001 && t > 0.0;\n}`),T.uniforms.add(new y(\"perScreenPixelRatio\",((e,r)=>r.camera.perScreenPixelRatio))),T.code.add(S`\n      vec4 toFront(vec4 displacedPosScreen, vec3 posLeft, vec3 posRight, vec3 prev, float lineWidth) {\n        // Project displaced position back to camera space\n        vec3 displacedPos = inverseProject(displacedPosScreen);\n\n        // Calculate the plane that we want the marker to lie in. Note that this will always be an approximation since ribbon lines are generally\n        // not planar and we do not know the actual position of the displaced prev vertices (they are offset in screen space, too).\n        vec3 planeNormal = normalize(cross(posLeft - posRight, posLeft - prev));\n        vec3 planeOrigin = posLeft;\n\n        ${M.hasCap?\"\\n                if(prev.z > posLeft.z) {\\n                  vec2 diff = posLeft.xy - posRight.xy;\\n                  planeOrigin.xy += perpendicular(diff) / 2.0;\\n                }\\n              \":\"\"};\n\n        // Move the plane towards the camera by a margin dependent on the line width (approximated in world space). This tolerance corrects for the\n        // non-planarity in most cases, but sharp joins can place the prev vertices at arbitrary positions so markers can still clip.\n        float offset = lineWidth * perScreenPixelRatio;\n        planeOrigin *= (1.0 - offset);\n\n        // Intersect camera ray with the plane and make sure it is within clip space\n        vec3 rayDir = normalize(displacedPos);\n        vec3 intersection;\n        if (rayIntersectPlane(rayDir, planeOrigin, planeNormal, intersection) && intersection.z < -nearFar[0] && intersection.z > -nearFar[1]) {\n          return vec4(intersection.xyz, 1.0);\n        }\n\n        // Fallback: use depth of pos or prev, whichever is closer to the camera\n        float minDepth = planeOrigin.z > prev.z ? length(planeOrigin) : length(prev);\n        displacedPos *= minDepth / length(displacedPos);\n        return vec4(displacedPos.xyz, 1.0);\n      }\n  `)),g(T),a(D),T.code.add(S`void main(void) {\nif (uv0.y == 0.0) {\ngl_Position = vec4(1e038, 1e038, 1e038, 1.0);\n}\nelse {\nfloat lineWidth = getLineWidth();\nfloat screenMarkerSize = getScreenMarkerSize();\nvec4 pos  = view * vec4(position.xyz, 1.0);\nvec4 prev = view * vec4(auxpos1.xyz, 1.0);\nclip(pos, prev);`),N?(M.hideOnShortSegments&&T.code.add(S`if (areWorldMarkersHidden(pos, prev)) {\ngl_Position = vec4(1e038, 1e038, 1e038, 1.0);\nreturn;\n}`),T.code.add(S`pos.xyz = displace(pos.xyz, prev.xyz, getWorldMarkerSize(pos));\nvec4 displacedPosScreen = projectAndScale(pos);`)):(T.code.add(S`vec4 posScreen = projectAndScale(pos);\nvec4 prevScreen = projectAndScale(prev);\nvec4 displacedPosScreen = posScreen;\ndisplacedPosScreen.xy = displace(posScreen.xy, prevScreen.xy, screenMarkerSize);`),M.space===j.Screen&&T.code.add(S`vec2 displacementDirU = perpendicular(normalizedSegment(posScreen.xy, prevScreen.xy));\nvec3 lineRight = inverseProject(posScreen + lineWidth * vec4(displacementDirU.xy, 0.0, 0.0));\nvec3 lineLeft = pos.xyz + (pos.xyz - lineRight);\npos = toFront(displacedPosScreen, lineLeft, lineRight, prev.xyz, lineWidth);\ndisplacedPosScreen = projectAndScale(pos);`)),T.code.add(S`\n        ${k?\"depth = pos.z;\":\"\"}\n        linearDepth = calculateLinearDepth(nearFar,pos.z);\n\n        // Convert back into NDC\n        displacedPosScreen.xy = (displacedPosScreen.xy / viewport.zw) * displacedPosScreen.w;\n\n        // Convert texture coordinate into [0,1]\n        vUV = (uv0 + 1.0) / 2.0;\n\n        ${N?\"\":\"vUV *= displacedPosScreen.w;\"}\n\n        ${M.hasTip?\"vLineWidth = lineWidth;\":\"\"}\n\n        vSize = screenMarkerSize;\n        vColor = getColor();\n\n        // Use camera space for slicing\n        vpos = pos.xyz;\n\n        gl_Position = displacedPosScreen;\n      }\n    }\n  `),k&&D.include(d,M),D.include(n,M),A.uniforms.add(new w(\"intrinsicColor\",(e=>e.color)),new P(\"tex\",(e=>e.markerTexture))),A.include(v),D.constants.add(\"texelSize\",\"float\",1/e),A.code.add(S`float markerAlpha(vec2 samplePos) {\nsamplePos += vec2(0.5, -0.5) * texelSize;\nfloat sdf = rgba2float(texture(tex, samplePos)) - 0.5;\nfloat distance = sdf * vSize;\ndistance -= 0.5;\nreturn clamp(0.5 - distance, 0.0, 1.0);\n}`),M.hasTip&&(D.constants.add(\"relativeMarkerSize\",\"float\",r/e),D.constants.add(\"relativeTipLineWidth\",\"float\",o),A.code.add(S`\n    float tipAlpha(vec2 samplePos) {\n      // Convert coordinates s.t. they are in pixels and relative to the tip of an arrow marker\n      samplePos -= vec2(0.5, 0.5 + 0.5 * relativeMarkerSize);\n      samplePos *= vSize;\n\n      float halfMarkerSize = 0.5 * relativeMarkerSize * vSize;\n      float halfTipLineWidth = 0.5 * max(1.0, relativeTipLineWidth * vLineWidth);\n\n      ${N?\"halfTipLineWidth *= fwidth(samplePos.y);\":\"\"}\n\n      float distance = max(abs(samplePos.x) - halfMarkerSize, abs(samplePos.y) - halfTipLineWidth);\n      return clamp(0.5 - distance, 0.0, 1.0);\n    }\n  `)),D.constants.add(\"symbolAlphaCutoff\",\"float\",p),A.code.add(S`\n  void main() {\n    discardBySlice(vpos);\n    ${k?\"terrainDepthTest(depth);\":\"\"}\n\n    vec4 finalColor = intrinsicColor * vColor;\n\n    ${N?\"vec2 samplePos = vUV;\":\"vec2 samplePos = vUV * gl_FragCoord.w;\"}\n\n    ${M.hasTip?\"finalColor.a *= max(markerAlpha(samplePos), tipAlpha(samplePos));\":\"finalColor.a *= markerAlpha(samplePos);\"}\n\n    ${M.output===t.ObjectAndLayerIdColor?S`finalColor.a = 1.0;`:\"\"}\n\n    if (finalColor.a < symbolAlphaCutoff) {\n      discard;\n    }\n\n    ${M.output===t.Alpha?S`fragColor = vec4(finalColor.a);`:\"\"}\n    ${M.output===t.Color?S`fragColor = highlightSlice(finalColor, vpos);`:\"\"}\n    ${M.output===t.Color&&M.transparencyPassType===z.Color?\"fragColor = premultiplyAlpha(fragColor);\":\"\"}\n    ${M.output===t.Highlight?S`fragColor = vec4(1.0);`:\"\"}\n    ${M.output===t.Depth?S`outputDepth(linearDepth);`:\"\"}\n  }\n  `),D}const D=Object.freeze(Object.defineProperty({__proto__:null,build:M},Symbol.toStringTag,{value:\"Module\"}));export{D as L,M as b};\n","/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{ShaderOutput as e}from\"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js\";import{SliceDraw as o}from\"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js\";import{Transform as r}from\"../views/3d/webgl-engine/core/shaderLibrary/Transform.glsl.js\";import{VertexColor as i}from\"../views/3d/webgl-engine/core/shaderLibrary/attributes/VertexColor.glsl.js\";import{OutputHighlight as t}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js\";import{symbolAlphaCutoff as s}from\"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaCutoff.js\";import{addProjViewLocalOrigin as l}from\"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js\";import{Float4PassUniform as a}from\"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js\";import{FloatPassUniform as d}from\"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js\";import{glsl as n}from\"../views/3d/webgl-engine/core/shaderModules/interfaces.js\";import{ShaderBuilder as g}from\"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js\";import{VertexAttribute as c}from\"../views/3d/webgl-engine/lib/VertexAttribute.js\";function u(u){const m=new g,{vertex:p,fragment:w}=m;return m.include(r,u),m.include(i,u),l(p,u),m.attributes.add(c.POSITION,\"vec3\"),m.varyings.add(\"vpos\",\"vec3\"),p.code.add(n`void main(void) {\nvpos = position;\nforwardNormalizedVertexColor();\ngl_Position = transformPosition(proj, view, vpos);\n}`),u.output===e.Highlight&&m.include(t,u),m.include(o,u),w.uniforms.add(new d(\"alphaCoverage\",((e,o)=>Math.min(1,e.width*o.camera.pixelRatio)))),u.hasVertexColors||w.uniforms.add(new a(\"constantColor\",(e=>e.color))),w.code.add(n`\n  void main() {\n    discardBySlice(vpos);\n\n    vec4 color = ${u.hasVertexColors?\"vColor\":\"constantColor\"};\n\n    ${u.output===e.ObjectAndLayerIdColor?n`color.a = 1.0;`:\"\"}\n\n    if (color.a < ${n.float(s)}) {\n      discard;\n    }\n\n    ${u.output===e.Color?n`fragColor = highlightSlice(color, vpos);`:\"\"}\n    ${u.output===e.Highlight?n`outputHighlight();`:\"\"}\n  }\n  `),m}const m=Object.freeze(Object.defineProperty({__proto__:null,build:u},Symbol.toStringTag,{value:\"Module\"}));export{m as N,u as b};\n","/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{ForwardLinearDepth as e,addNearFar as i}from\"../views/3d/webgl-engine/core/shaderLibrary/ForwardLinearDepth.glsl.js\";import{ShaderOutput as o}from\"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js\";import{SliceDraw as a}from\"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js\";import{Transform as r}from\"../views/3d/webgl-engine/core/shaderLibrary/Transform.glsl.js\";import{PathVertexPosition as l}from\"../views/3d/webgl-engine/core/shaderLibrary/attributes/PathVertexPosition.glsl.js\";import{OutputDepth as s}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js\";import{OutputHighlight as n}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js\";import{EvaluateAmbientOcclusion as d}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/EvaluateAmbientOcclusion.glsl.js\";import{EvaluateSceneLighting as t,addAmbientBoostFactor as c,addLightingGlobalFactor as g}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/EvaluateSceneLighting.glsl.js\";import{addMainLightIntensity as m}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MainLighting.glsl.js\";import{multipassTerrainTest as p}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js\";import{Normals as v}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/Normals.glsl.js\";import{NormalUtils as h}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/NormalUtils.glsl.js\";import{ReadShadowMapDraw as u}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/ReadShadowMap.glsl.js\";import{ColorConversion as b}from\"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js\";import{addProjViewLocalOrigin as w,addViewNormal as f,addCameraPosition as y}from\"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js\";import{Float3PassUniform as j}from\"../views/3d/webgl-engine/core/shaderModules/Float3PassUniform.js\";import{FloatPassUniform as L}from\"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js\";import{glsl as P}from\"../views/3d/webgl-engine/core/shaderModules/interfaces.js\";import{ShaderBuilder as S}from\"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js\";import{TransparencyPassType as C}from\"../views/3d/webgl-engine/lib/TransparencyPassType.js\";function O(O){const D=new S,{vertex:A,fragment:F}=D;switch(w(A,O),D.varyings.add(\"vpos\",\"vec3\"),D.include(l,O),O.output!==o.Color&&O.output!==o.Alpha||(D.include(r,O),D.include(u,O),D.include(e,O),D.varyings.add(\"vnormal\",\"vec3\"),D.varyings.add(\"vcolor\",\"vec4\"),O.multipassEnabled&&D.varyings.add(\"depth\",\"float\"),A.code.add(P`\n      void main() {\n        vpos = calculateVPos();\n        vnormal = normalize(localNormal());\n\n        ${O.multipassEnabled?\"depth = (view * vec4(vpos, 1.0)).z;\":\"\"}\n        gl_Position = transformPosition(proj, view, vpos);\n\n        ${O.output===o.Color?\"forwardLinearDepth();\":\"\"}\n\n        vcolor = getColor();\n      }\n    `)),D.include(p,O),O.output){case o.Alpha:D.include(a,O),F.uniforms.add(new L(\"opacity\",(e=>e.opacity))),F.code.add(P`\n      void main() {\n        discardBySlice(vpos);\n        ${O.multipassEnabled?\"terrainDepthTest(depth);\":\"\"}\n        float combinedOpacity = vcolor.a * opacity;\n        fragColor = vec4(combinedOpacity);\n      }\n    `);break;case o.Color:D.include(a,O),D.include(t,O),D.include(d,O),D.include(u,O),D.include(v,O),y(F,O),c(F),g(F),F.uniforms.add(A.uniforms.get(\"localOrigin\"),new j(\"ambient\",(e=>e.ambient)),new j(\"diffuse\",(e=>e.diffuse)),new j(\"specular\",(e=>e.specular)),new L(\"opacity\",(e=>e.opacity))),F.include(b),m(F),F.code.add(P`\n        void main() {\n          discardBySlice(vpos);\n          ${O.multipassEnabled?\"terrainDepthTest(depth);\":\"\"}\n\n          shadingParams.viewDirection = normalize(vpos - cameraPosition);\n          shadingParams.normalView = vnormal;\n          vec3 normal = shadingNormal(shadingParams);\n          float ssao = evaluateAmbientOcclusionInverse();\n\n          float additionalAmbientScale = additionalDirectedAmbientLight(vpos + localOrigin);\n          vec3 additionalLight = ssao * mainLightIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\n          ${O.receiveShadows?\"float shadow = readShadowMap(vpos, linearDepth);\":O.spherical?\"float shadow = lightingGlobalFactor * (1.0 - additionalAmbientScale);\":\"float shadow = 0.0;\"}\n          vec3 albedo = vcolor.rgb * max(ambient, diffuse); // combine the old material parameters into a single one\n          float combinedOpacity = vcolor.a * opacity;\n          albedo += 0.25 * specular; // don't completely ignore specular for now\n\n          vec3 shadedColor = evaluateSceneLighting(normal, albedo, shadow, 1.0 - ssao, additionalLight);\n          fragColor = vec4(shadedColor, combinedOpacity);\n          fragColor = highlightSlice(fragColor, vpos);\n          ${O.transparencyPassType===C.Color?\"fragColor = premultiplyAlpha(fragColor);\":\"\"}\n        }\n      `);break;case o.Depth:case o.Shadow:case o.ShadowHighlight:case o.ShadowExcludeHighlight:D.include(r,O),i(D),D.varyings.add(\"depth\",\"float\"),A.code.add(P`void main() {\nvpos = calculateVPos();\ngl_Position = transformPositionWithDepth(proj, view, vpos, nearFar, depth);\n}`),D.include(a,O),D.include(s,O),F.code.add(P`void main() {\ndiscardBySlice(vpos);\noutputDepth(depth);\n}`);break;case o.Normal:D.include(r,O),D.include(h,O),f(A),D.varyings.add(\"vnormal\",\"vec3\"),A.code.add(P`void main(void) {\nvpos = calculateVPos();\nvnormal = normalize((viewNormal * vec4(localNormal(), 1.0)).xyz);\ngl_Position = transformPosition(proj, view, vpos);\n}`),D.include(a,O),F.code.add(P`void main() {\ndiscardBySlice(vpos);\nvec3 normal = normalize(vnormal);\nif (gl_FrontFacing == false) normal = -normal;\nfragColor = vec4(vec3(0.5) + 0.5 * normal, 1.0);\n}`);break;case o.Highlight:D.include(r,O),D.include(h,O),D.varyings.add(\"vnormal\",\"vec3\"),A.code.add(P`void main(void) {\nvpos = calculateVPos();\ngl_Position = transformPosition(proj, view, vpos);\n}`),D.include(a,O),D.include(n,O),F.code.add(P`void main() {\ndiscardBySlice(vpos);\noutputHighlight();\n}`)}return D}const D=Object.freeze(Object.defineProperty({__proto__:null,build:O},Symbol.toStringTag,{value:\"Module\"}));export{D as P,O as b};\n","/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{addNearFar as e,addLinearDepth as o}from\"../views/3d/webgl-engine/core/shaderLibrary/ForwardLinearDepth.glsl.js\";import{ShaderOutput as t}from\"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutput.js\";import{SliceDraw as r}from\"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js\";import{Transform as a}from\"../views/3d/webgl-engine/core/shaderLibrary/Transform.glsl.js\";import{VertexColor as i}from\"../views/3d/webgl-engine/core/shaderLibrary/attributes/VertexColor.glsl.js\";import{OutputDepth as l}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js\";import{OutputHighlight as n}from\"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js\";import{multipassTerrainTest as c}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js\";import{VisualVariables as d}from\"../views/3d/webgl-engine/core/shaderLibrary/shading/VisualVariables.glsl.js\";import{symbolAlphaCutoff as s}from\"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaCutoff.js\";import{ColorConversion as p}from\"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js\";import{addProjViewLocalOrigin as g,addCameraPosition as v}from\"../views/3d/webgl-engine/core/shaderLibrary/util/View.glsl.js\";import{Float4PassUniform as u}from\"../views/3d/webgl-engine/core/shaderModules/Float4PassUniform.js\";import{FloatPassUniform as m}from\"../views/3d/webgl-engine/core/shaderModules/FloatPassUniform.js\";import{glsl as f}from\"../views/3d/webgl-engine/core/shaderModules/interfaces.js\";import{ShaderBuilder as h}from\"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js\";import{TransparencyPassType as w}from\"../views/3d/webgl-engine/lib/TransparencyPassType.js\";import{VertexAttribute as b}from\"../views/3d/webgl-engine/lib/VertexAttribute.js\";import{Style as y}from\"../views/3d/webgl-engine/materials/PatternStyle.js\";const S=.70710678118,j=S,C=.08715574274;function x(x){const P=new h,R=x.multipassEnabled&&(x.output===t.Color||x.output===t.Alpha),{vertex:$,fragment:D,attributes:V,varyings:A}=P;g($,x),P.include(a,x),P.include(i,x),P.include(d,x),x.draped?$.uniforms.add(new m(\"worldToScreenRatio\",((e,o)=>1/o.screenToPCSRatio))):V.add(b.BOUNDINGRECT,\"mat3\"),V.add(b.POSITION,\"vec3\"),V.add(b.UVMAPSPACE,\"vec4\"),x.vvColor&&V.add(b.COLORFEATUREATTRIBUTE,\"float\"),A.add(\"vColor\",\"vec4\"),A.add(\"vpos\",\"vec3\"),A.add(\"vuv\",\"vec2\"),R&&A.add(\"depth\",\"float\"),$.uniforms.add(new u(\"uColor\",(e=>e.color)));const L=x.style===y.ForwardDiagonal||x.style===y.BackwardDiagonal||x.style===y.DiagonalCross;L&&$.code.add(f`\n      const mat2 rotate45 = mat2(${f.float(S)}, ${f.float(-j)},\n                                 ${f.float(j)}, ${f.float(S)});\n    `),x.draped||(v($,x),$.uniforms.add(new m(\"worldToScreenPerDistanceRatio\",((e,o)=>1/o.camera.perScreenPixelRatio))),$.code.add(f`vec3 projectPointToLineSegment(vec3 center, vec3 halfVector, vec3 point) {\nfloat projectedLength = dot(halfVector, point - center) / dot(halfVector, halfVector);\nreturn center + halfVector * clamp(projectedLength, -1.0, 1.0);\n}`),$.code.add(f`vec3 intersectRayPlane(vec3 rayDir, vec3 rayOrigin, vec3 planeNormal, vec3 planePoint) {\nfloat d = dot(planeNormal, planePoint);\nfloat t = (d - dot(planeNormal, rayOrigin)) / dot(planeNormal, rayDir);\nreturn rayOrigin + t * rayDir;\n}`),$.code.add(f`\n      float boundingRectDistanceToCamera() {\n        vec3 center = vec3(boundingRect[0][0], boundingRect[0][1], boundingRect[0][2]);\n        vec3 halfU = vec3(boundingRect[1][0], boundingRect[1][1], boundingRect[1][2]);\n        vec3 halfV = vec3(boundingRect[2][0], boundingRect[2][1], boundingRect[2][2]);\n        vec3 n = normalize(cross(halfU, halfV));\n\n        vec3 viewDir = - vec3(view[0][2], view[1][2], view[2][2]);\n\n        float viewAngle = dot(viewDir, n);\n        float minViewAngle = ${f.float(C)};\n\n        if (abs(viewAngle) < minViewAngle) {\n          // view direction is (almost) parallel to plane -> clamp it to min angle\n          float normalComponent = sign(viewAngle) * minViewAngle - viewAngle;\n          viewDir = normalize(viewDir + normalComponent * n);\n        }\n\n        // intersect view direction with infinite plane that contains bounding rect\n        vec3 planeProjected = intersectRayPlane(viewDir, cameraPosition, n, center);\n\n        // clip to bounds by projecting to u and v line segments individually\n        vec3 uProjected = projectPointToLineSegment(center, halfU, planeProjected);\n        vec3 vProjected = projectPointToLineSegment(center, halfV, planeProjected);\n\n        // use to calculate the closest point to camera on bounding rect\n        vec3 closestPoint = uProjected + vProjected - center;\n\n        return length(closestPoint - cameraPosition);\n      }\n    `)),$.code.add(f`\n    vec2 scaledUV() {\n      vec2 uv = uvMapSpace.xy ${L?\" * rotate45\":\"\"};\n      vec2 uvCellOrigin = uvMapSpace.zw ${L?\" * rotate45\":\"\"};\n\n      ${x.draped?\"\":f`\n            float distanceToCamera = boundingRectDistanceToCamera();\n            float worldToScreenRatio = worldToScreenPerDistanceRatio / distanceToCamera;\n          `}\n\n      // Logarithmically discretize ratio to avoid jittering\n      float step = 0.1;\n      float discreteWorldToScreenRatio = log(worldToScreenRatio);\n      discreteWorldToScreenRatio = ceil(discreteWorldToScreenRatio / step) * step;\n      discreteWorldToScreenRatio = exp(discreteWorldToScreenRatio);\n\n      vec2 uvOffset = mod(uvCellOrigin * discreteWorldToScreenRatio, ${f.float(x.patternSpacing)});\n      return uvOffset + (uv * discreteWorldToScreenRatio);\n    }\n  `);const O=x.output===t.Depth;return O&&(P.include(l,x),e(P),o(P)),$.code.add(f`\n    void main(void) {\n      vuv = scaledUV();\n      vpos = position;\n      ${R?\"depth = (view * vec4(vpos, 1.0)).z;\":\"\"}\n      forwardNormalizedVertexColor();\n      ${x.hasVertexColors?\"vColor *= uColor;\":x.vvColor?\"vColor = uColor * interpolateVVColor(colorFeatureAttribute);\":\"vColor = uColor;\"}\n      gl_Position = ${O?f`transformPositionWithDepth(proj, view, vpos, nearFar, linearDepth);`:f`transformPosition(proj, view, vpos);`}\n    }\n  `),P.include(r,x),D.include(p),x.draped&&D.uniforms.add(new m(\"texelSize\",((e,o)=>1/o.camera.pixelRatio))),x.output===t.Highlight&&P.include(n,x),R&&P.include(c,x),x.output!==t.Highlight&&(D.code.add(f`\n      const float lineWidth = ${f.float(x.lineWidth)};\n      const float spacing = ${f.float(x.patternSpacing)};\n      const float spacingINV = ${f.float(1/x.patternSpacing)};\n\n      float coverage(float p, float txlSize) {\n        p = mod(p, spacing);\n\n        float halfTxlSize = txlSize / 2.0;\n\n        float start = p - halfTxlSize;\n        float end = p + halfTxlSize;\n\n        float coverage = (ceil(end * spacingINV) - floor(start * spacingINV)) * lineWidth;\n        coverage -= min(lineWidth, mod(start, spacing));\n        coverage -= max(lineWidth - mod(end, spacing), 0.0);\n\n        return coverage / txlSize;\n      }\n    `),x.draped||D.code.add(f`const int maxSamples = 5;\nfloat sampleAA(float p) {\nvec2 dxdy = abs(vec2(dFdx(p), dFdy(p)));\nfloat fwidth = dxdy.x + dxdy.y;\nivec2 samples = 1 + ivec2(clamp(dxdy, 0.0, float(maxSamples - 1)));\nvec2 invSamples = 1.0 / vec2(samples);\nfloat accumulator = 0.0;\nfor (int j = 0; j < maxSamples; j++) {\nif(j >= samples.y) {\nbreak;\n}\nfor (int i = 0; i < maxSamples; i++) {\nif(i >= samples.x) {\nbreak;\n}\nvec2 step = vec2(i,j) * invSamples - 0.5;\naccumulator += coverage(p + step.x * dxdy.x + step.y * dxdy.y, fwidth);\n}\n}\naccumulator /= float(samples.x * samples.y);\nreturn accumulator;\n}`)),D.code.add(f`\n    void main() {\n      discardBySlice(vpos);\n      ${R?\"terrainDepthTest(depth);\":\"\"}\n      vec4 color = vColor;\n      color = highlightSlice(color, vpos);\n\n      ${x.output!==t.Highlight?f`color.a *= ${T(x)};`:\"\"}\n\n      ${x.output===t.ObjectAndLayerIdColor?f`color.a = 1.0;`:\"\"}\n\n      if (color.a < ${f.float(s)}) {\n        discard;\n      }\n\n      ${x.output===t.Alpha?f`fragColor = vec4(color.a);`:\"\"}\n\n      ${x.output===t.Color?f`fragColor = color; ${x.transparencyPassType===w.Color?\"fragColor = premultiplyAlpha(fragColor);\":\"\"}`:\"\"}\n      ${x.output===t.Highlight?f`outputHighlight();`:\"\"}\n      ${x.output===t.Depth?f`outputDepth(linearDepth);`:\"\"};\n    }\n  `),P}function T(e){function o(o){return e.draped?f`coverage(vuv.${o}, texelSize)`:f`sampleAA(vuv.${o})`}switch(e.style){case y.ForwardDiagonal:case y.Horizontal:return o(\"y\");case y.BackwardDiagonal:case y.Vertical:return o(\"x\");case y.DiagonalCross:case y.Cross:return f`\n        1.0 - (1.0 - ${o(\"x\")}) * (1.0 - ${o(\"y\")})\n      `;default:return\"0.0\"}}const P=Object.freeze(Object.defineProperty({__proto__:null,build:x},Symbol.toStringTag,{value:\"Module\"}));export{P,x as b};\n","/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.28/esri/copyright.txt for details.\n*/\nimport{f as e}from\"../../../../../../chunks/vec2f64.js\";import{PositionAttribute as o}from\"./PositionAttribute.glsl.js\";import{Float2PassUniform as i}from\"../../shaderModules/Float2PassUniform.js\";import{Float3PassUniform as r}from\"../../shaderModules/Float3PassUniform.js\";import{Float4sPassUniform as t}from\"../../shaderModules/Float4sPassUniform.js\";import{FloatsPassUniform as a}from\"../../shaderModules/FloatsPassUniform.js\";import{glsl as l}from\"../../shaderModules/interfaces.js\";import{VertexAttribute as v}from\"../../../lib/VertexAttribute.js\";import{vvColorNumber as s,VisualVariablePassParameters as c}from\"../../../materials/VisualVariablePassParameters.js\";const p=8;function f(e,c){const f=v.FEATUREVALUE;e.attributes.add(f,\"vec4\");const n=e.vertex;n.code.add(l`\n  bool isCapVertex() {\n    return ${f}.w == 1.0;\n  }\n  `),n.uniforms.add(new i(\"size\",(e=>e.size))),c.vvSize?(n.uniforms.add(new r(\"vvSizeMinSize\",(e=>e.vvSize.minSize)),new r(\"vvSizeMaxSize\",(e=>e.vvSize.maxSize)),new r(\"vvSizeOffset\",(e=>e.vvSize.offset)),new r(\"vvSizeFactor\",(e=>e.vvSize.factor))),n.code.add(l`\n    vec2 getSize() {\n      return size * clamp(vvSizeOffset + ${f}.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize).xz;\n    }\n    `)):n.code.add(l`vec2 getSize(){\nreturn size;\n}`),c.vvOpacity?(n.constants.add(\"vvOpacityNumber\",\"int\",p),n.uniforms.add(new a(\"vvOpacityValues\",(e=>e.vvOpacity.values),p),new a(\"vvOpacityOpacities\",(e=>e.vvOpacity.opacityValues),p)),n.code.add(l`\n    vec4 applyOpacity(vec4 color) {\n      float value = ${f}.z;\n      if (value <= vvOpacityValues[0]) {\n        return vec4( color.xyz, vvOpacityOpacities[0]);\n      }\n\n      for (int i = 1; i < vvOpacityNumber; ++i) {\n        if (vvOpacityValues[i] >= value) {\n          float f = (value - vvOpacityValues[i-1]) / (vvOpacityValues[i] - vvOpacityValues[i-1]);\n          return vec4( color.xyz, mix(vvOpacityOpacities[i-1], vvOpacityOpacities[i], f));\n        }\n      }\n\n      return vec4( color.xyz, vvOpacityOpacities[vvOpacityNumber - 1]);\n    }\n    `)):n.code.add(l`vec4 applyOpacity(vec4 color){\nreturn color;\n}`),c.vvColor?(n.constants.add(\"vvColorNumber\",\"int\",s),n.uniforms.add(new a(\"vvColorValues\",(e=>e.vvColor.values),s),new t(\"vvColorColors\",(e=>e.vvColor.colors),s)),n.code.add(l`\n    vec4 getColor() {\n      float value = ${f}.y;\n      if (value <= vvColorValues[0]) {\n        return applyOpacity(vvColorColors[0]);\n      }\n\n      for (int i = 1; i < vvColorNumber; ++i) {\n        if (vvColorValues[i] >= value) {\n          float f = (value - vvColorValues[i-1]) / (vvColorValues[i] - vvColorValues[i-1]);\n          return applyOpacity(mix(vvColorColors[i-1], vvColorColors[i], f));\n        }\n      }\n\n      return applyOpacity(vvColorColors[vvColorNumber - 1]);\n    }\n    `)):n.code.add(l`vec4 getColor(){\nreturn applyOpacity(vec4(1, 1, 1, 1));\n}`),e.include(o),e.attributes.add(v.PROFILERIGHT,\"vec4\"),e.attributes.add(v.PROFILEUP,\"vec4\"),e.attributes.add(v.PROFILEVERTEXANDNORMAL,\"vec4\"),n.code.add(l`vec3 calculateVPos() {\nvec2 size = getSize();\nvec3 origin = position;\nvec3 right = profileRight.xyz;\nvec3 up = profileUp.xyz;\nvec3 forward = cross(up, right);\nvec2 profileVertex = profileVertexAndNormal.xy * size;\nvec2 profileNormal = profileVertexAndNormal.zw;\nfloat positionOffsetAlongProfilePlaneNormal = 0.0;\nfloat normalOffsetAlongProfilePlaneNormal = 0.0;`),n.code.add(l`if(!isCapVertex()) {\nvec2 rotationRight = vec2(profileRight.w, profileUp.w);\nfloat maxDistance = length(rotationRight);`),n.code.add(l`rotationRight = maxDistance > 0.0 ? normalize(rotationRight) : vec2(0, 0);\nfloat rx = dot(profileVertex, rotationRight);\nif (abs(rx) > maxDistance) {\nvec2 rotationUp = vec2(-rotationRight.y, rotationRight.x);\nfloat ry = dot(profileVertex, rotationUp);\nprofileVertex = rotationRight * maxDistance * sign(rx) + rotationUp * ry;\n}\n}else{\npositionOffsetAlongProfilePlaneNormal = profileRight.w * size[0];\nnormalOffsetAlongProfilePlaneNormal = profileUp.w;\n}\nvec3 offset = right * profileVertex.x + up * profileVertex.y + forward * positionOffsetAlongProfilePlaneNormal;\nreturn origin + offset;\n}`),n.code.add(l`vec3 localNormal() {\nvec3 right = profileRight.xyz;\nvec3 up = profileUp.xyz;\nvec3 forward = cross(up, right);\nvec2 profileNormal = profileVertexAndNormal.zw;\nvec3 normal = right * profileNormal.x + up * profileNormal.y;\nif(isCapVertex()) {\nnormal += forward * profileUp.w;\n}\nreturn normal;\n}`)}class n extends c{constructor(){super(...arguments),this.size=e(1,1)}}export{f as PathVertexPosition,n as PathVertexPositionPassParameters};\n"],"names":[],"sourceRoot":""}